CHAPTER SEVEN

The Engineer

Beijing, China — January 2030

Wei Chen's apartment was in one of Beijing's newer developments—thirty floors of glass and steel, everything modern and efficient. Smart systems controlled lighting, temperature, security. The building had its own automated delivery network. You could live here for weeks without seeing another human being.

He usually liked that. Efficiency. Minimal friction.

Tonight, it felt lonely.

Lihua was asleep. His wife, Mei, was working late again—she was an architect, designing the automated factories Wei's frameworks made possible. They were partners in optimization, building the future together.

Except Wei couldn't stop thinking about what that future actually meant.

He opened his laptop, pulled up the message from Elena Volkov. They'd arranged a video call for tonight—late evening in Beijing, morning in Washington DC.

The call connected. Elena's face appeared—sharp gray hair, intelligent eyes, a warm smile that didn't match the seriousness of her expression.

"Dr. Chen," she said in Mandarin. "Thank you for agreeing to speak."

"Your message was intriguing. And unsettling." Wei kept his Mandarin formal. "You said you're building human alternatives. What does that mean?"

"May I ask you a question first?" Elena switched to English—probably more secure. "When you designed the optimal dependency framework, what problem were you trying to solve?"

Wei considered. "Economic stability. Strategic advantage. How to create sustainable relationships where partners remain aligned with Chinese interests."

"And you succeeded brilliantly. Your models work exactly as designed." She paused. "But did you ever ask whether they *should* work?"

"That's a moral question. I'm an economist."

"Economists who pretend their work doesn't have moral implications create disasters they call optimal." Elena's tone was gentle but firm. "Dr. Chen, your frameworks are displacing hundreds of millions of people. Making them economically superfluous. Did you model what happens to humans who aren't needed by the systems that govern their lives?"

Wei felt defensive. "The models account for social disruption. Governments provide transition support, retraining programs—"

"Retrain for what? Your own projections show automation accelerating across all sectors. There aren't jobs to retrain for. There's just... displacement. At scale. Permanent."

She wasn't wrong. Wei had seen the projections. The Committee celebrated them as strategic victories.

But hearing them described as human elimination made his stomach tighten.

"What's your alternative?" he asked. "Stop technological progress? That's naive."

"No. Build parallel systems. Small-scale, human-controlled, resilient. Communities that can feed themselves, power themselves, maintain their own infrastructure without depending on global corporations or government permission." Elena's eyes were steady. "We can't stop automation. But we can create spaces where people aren't dependent on it."

"That's not scalable."

"No. But it's survivable. And when the automated systems fail—and they will fail, Dr. Chen, because they're optimized for efficiency, not resilience—the communities with human skills and local resources will be the ones that make it through."

Wei thought about Lihua's question. *What's left for people?*

"Why are you telling me this?" he asked.

"Because you're brilliant. You understand systems better than almost anyone. And I think you're starting to realize that the systems you designed have a fatal flaw."

"What flaw?"

Elena smiled sadly. "They optimized away the only thing that matters. Human meaning. Purpose. Connection. The things that make life worth living. Your systems are efficient. But they're empty. And eventually, people will stop participating in empty systems, even if they're optimal."

* * *

The call lasted two hours.

Elena showed him the network—faces from around the world. Emma Chen in Ohio, teaching manufacturing skills to displaced workers. Maxim Orlov in Russia, training young people to repair machines. Amara Okafor in Kenya, building agricultural cooperatives that didn't depend on imported food.

"These are small pictures," Elena said. "None of them will appear in your economic models. But they're real. They help people. They create meaning in a world increasingly optimized against it."

Wei asked questions. Sharp ones. How do you scale? How do you fund this? What's the end goal?

Elena's answers were honest. "We don't scale in the traditional sense. We replicate—each community building its own version. Funding is mostly local, some donations. And there's no end goal except survival with dignity. We're not trying to overthrow anything. Just build alternatives for people your systems leave behind."

After they disconnected, Wei sat in his dark apartment, thinking.

The network Elena showed him was inefficient. Unscalable. Economically marginal.

But the people in it seemed... alive. Purposeful. Connected to something beyond optimization.

He pulled up his own models. The ones that had earned him recognition, promotions, access to the Committee.

Optimal dependency. Automated production. Strategic control.

All of it designed to make human labor unnecessary.

He'd called it progress.

What if it was just elimination with better engineering?

* * *

Two days later, Wei attended a planning meeting at the think tank where he worked.

The topic: full automation timelines for remaining sectors.

"Healthcare is ready for large-scale deployment," said Zhang, his colleague. "Diagnostic AI, surgical robots, automated pharmaceutical production. We can reduce human medical staff by 70% within five years."

"Education?" someone asked.

"AI tutoring systems are outperforming human teachers in trials. Personalized learning, infinite patience, no salary costs. Implementation beginning in pilot cities next year."

"What about social resistance?"

"Minimal. The systems work better than human alternatives. Parents want the best for their children. Workers understand they can't compete." Zhang pulled up a slide. "The question isn't whether to automate these sectors. It's how fast."

Wei listened with growing discomfort.

These weren't abstract projections anymore. They were his daughter's teachers, his family's doctors. Real people with skills and purpose.

Being optimized away.

"What happens to the displaced workers?" he asked.

The room looked at him. The question seemed odd, coming from him—Wei Chen, architect of optimal dependency, who'd never worried about human costs before.

Zhang shrugged. "Retraining. Social support. Market forces will create new equilibria."

"New equilibria where millions of people aren't economically necessary?"

"Economically unnecessary doesn't mean they stop existing, Chen. They'll adapt. Find new roles. That's how creative destruction works."

Wei wanted to ask: adapt to *what*? Find roles doing *what*? But he stayed quiet.

After the meeting, Zhang pulled him aside. "You okay? You seemed off in there."

"Fine. Just thinking about implementation challenges."

"Good. The Committee is watching your work closely. Your frameworks are proving out. Don't get distracted by second-order concerns."

Second-order concerns. Like what happened to billions of humans in a world that didn't need them.

Wei went home early.

* * *

That evening, Lihua asked for help with her homework. Economics.

"We're studying comparative advantage," she said. "Why nations trade based on what they're relatively better at producing."

"Classic theory. What's your question?"

"What happens when one nation is better at producing everything? Like, absolute advantage across all sectors?"

Wei smiled. "Good question. Theory says that's impossible—every nation has some comparative advantage. But in practice..."

"In practice China makes everything now. I looked it up. Thirty percent of global manufacturing. Dominant in almost every category." She looked at him. "So what happens to the countries with no advantages left?"

Wei felt the question like a physical blow.

This was his framework. Optimal dependency. Make partners need you for everything. Lock in control through comprehensive dominance.

He'd built it. Proved it worked. Called it strategic.

"They become dependent," he said quietly.

"On us."

"Yes."

Lihua nodded, thinking. "And then we control them. Not with armies. With economics."

"That's... a simplified version, but essentially yes."

"Is that good?"

"It's effective."

"That's not what I asked, Bàba. Is it *good*?"

Wei looked at his fifteen-year-old daughter. When had she started asking questions he couldn't answer?

"I don't know," he admitted. "I designed systems to be optimal. I didn't ask if they were good."

Lihua studied him. "You should probably ask that."

After she went to bed, Wei sat with Mei in their living room.

"Lihua asked me if economic dominance is good," he said.

Mei looked up from her tablet. "What did you tell her?"

"That I don't know. That I optimized for effectiveness, not ethics."

"That's honest."

"Is it enough?"

Mei set down her tablet, gave him her full attention. "What's bothering you? You've been different since New Year's."

Wei told her about Elena. The network. The conversation about human meaning in automated systems.

"She said the systems have a fatal flaw," he finished. "That they optimize away purpose. And eventually people stop participating in purposeless systems."

"Do you believe that?"

"I think..." Wei chose his words carefully. "I think we've spent years solving the wrong problem. We asked how to make systems more efficient. We should have asked what systems are *for*. What humans need from them beyond efficiency."

"You're the one who built the efficiency frameworks."

"I know. And they work. Brilliantly. That's what worries me." He looked at his wife. "What happens when our systems are so efficient they don't need people anymore? What do billions of humans do when they're economically obsolete?"

Mei was quiet for a long moment. "Are you thinking about leaving the think tank?"

"I don't know what I'm thinking. Just that something feels wrong. Like we've optimized toward a future nobody actually wants to live in."

"Can you change it?"

Wei laughed bitterly. "The Committee loves my work. My models are being implemented across seventeen countries. Hundreds of millions of people are experiencing what I designed. I can't stop it now."

"But you could do something else. With what you know."

Wei thought about the network. Small pictures. Inefficient. Human.

"Maybe," he said.

* * *

Over the next month, Wei started doing something he'd never done before: he went looking for the people his systems displaced.

Not in data. In person.

He visited a factory in Shenzhen where humanoid robots had replaced 90% of the workforce. Talked to the few humans left.

"I used to assemble phones," one man told him. "Did it for twelve years. Knew every component, every connection. Now I watch robots do it faster and better. I'm here to press the emergency stop if something goes wrong. That's my whole job now—wait for failure."

"What will you do when they don't need you anymore?"

The man shrugged. "No idea. I'm forty. Not young enough to retrain for tech work, not old enough to retire. Just... unnecessary."

Wei visited a logistics hub in Guangzhou. Autonomous vehicles, AI routing, automated loading. The manager was proud.

"We moved 100,000 packages yesterday with a staff of eight. Used to need two hundred people. The efficiency gains are incredible."

"What happened to the other 192 people?"

"They found other work, I assume. That's not my concern. My job is logistics optimization, and these systems are perfect."

Wei thought: I designed this. I wrote the frameworks that made this efficient. I never asked about the 192 people.

He visited a school piloting AI tutoring. The students loved it—personalized, patient, engaging.

The teachers were being retrained as "learning facilitators." Fewer of them needed. Lower status. Lower pay.

"Do you like the new system?" Wei asked one teacher.

"It's effective. The kids learn faster." She paused. "But I miss actually teaching. Now I just monitor screens and manage behavior issues. The AI does the real work. Makes me wonder why I'm here at all."

Everywhere Wei looked, he saw the same pattern. Efficient systems. Displaced people. Purposeless humans asking what they were for.

He'd designed this.

Called it optimal.

* * *

In March, Wei met with Elena again.

"I've been looking at the displacement," he said. "Talking to people affected by systems I helped design."

"And?"

"You were right. The models work perfectly. That's the problem. They're optimized for efficiency, not for human flourishing. And I don't know how to fix that without dismantling everything I built."

Elena's expression was sympathetic. "You can't fix it. The systems are too large, too entrenched. But you can build alternatives. Help the people your systems leave behind."

"How? I'm not a community organizer. I'm an economist who designed frameworks for control."

"Then use that knowledge. You understand these systems better than almost anyone. You know where they're fragile, where they'll fail, what people will need when they do." Elena leaned forward. "The network needs people who understand the big picture. Who can help communities prepare. You could do that."

Wei thought about it. His work had created economic dependency for hundreds of millions of people. Could he really help them escape it?

"What would that look like?"

"Share what you know. Where the systems are vulnerable. What skills matter when supply chains break. How communities can become resilient against the dependency you engineered." She smiled. "You spent years making people dependent. Spend some time helping them become independent."

"The government wouldn't approve."

"No. You'd have to be careful. Secret. But you're brilliant at systems thinking. You could figure it out."

Wei sat with that. His career, his reputation, possibly his freedom—all at risk if he helped people resist systems he'd designed for the Chinese state.

But Lihua's question haunted him: *Is it good?*

"I need to think about it," he said.

"Of course. But Chen? Whatever you decide, don't take too long. The systems are accelerating. People need help now."

* * *

The decision crystallized unexpectedly.

Wei was at a government reception—officials, think tank researchers, corporate executives. Celebrating another milestone in automation deployment.

Someone gave a toast: "To efficiency! To progress! To the optimal future!"

Everyone drank.

Wei looked around the room. Successful people, all of them. Engineers, economists, officials. Building systems that made human labor obsolete.

None of them seemed troubled by it.

He thought about the factory worker waiting for failure. The teacher monitoring screens. The logistics workers who'd vanished into "other work."

The 192 people who weren't his concern.

He thought about Lihua, asking what she'd do in a world where robots did everything.

He thought about Elena's network. Small pictures. Building lifeboats.

He set down his glass and left the reception early.

At home, he opened his encrypted messages. Typed carefully:

*Elena—I want to help. What do you need from me?*

The response came within minutes: *Everything you know about where the systems are fragile. What communities need to prepare. And maybe your help thinking through what comes after.*

*After what?*

*After the optimal systems collapse under their own logic. After people remember what they're for.*

Wei thought about that. The optimal systems collapsing. Not from attack. From emptiness.

He'd designed frameworks for efficiency. Never asked what efficiency was for.

Maybe it was time to ask.

*I'll help,* he typed. *Tell me what you need.*

* * *

Over the following months, Wei led a double life.

Publicly, he continued his work at the think tank. Delivered presentations. Refined models. Maintained his reputation as a brilliant systems designer.

Privately, he helped the network.

He shared research on supply chain vulnerabilities. Explained which systems were fragile, likely to fail first when pressures mounted. Identified skills that would matter when automated systems couldn't be maintained.

He helped Elena and her core team think through scenarios. What happens when automated factories can't get parts? When AI systems need maintenance expertise that's been eliminated? When the optimized systems encounter problems they weren't designed to handle?

"You're building anti-fragility," he told them on one call. "My systems are optimized for efficiency, which makes them brittle. Yours are inefficient but resilient. When conditions change—and they will—resilient survives, efficient fails."

Maxim laughed. "The Russian factory worker teaching obsolete skills will outlast the Chinese robot factory. There's poetry in that."

"There's truth in it," Wei corrected. "Automated systems require global supply chains, technical expertise, continuous maintenance. Remove any component and they fail. Your workshops? They work with whatever's available. That's anti-fragility."

Emma asked the hard question: "When do you think the systems start failing?"

Wei pulled up projections. "The automation is ahead of schedule. Displacement faster than anticipated. Within three to five years, we'll hit critical thresholds—unemployment so high that consumer demand collapses. Supply chains optimized so tight that any disruption cascades. Systems so complex that maintaining them requires expertise we've eliminated."

"And then?"

"Then things get chaotic. Not collapse, exactly. Uneven failure. Some regions maintain automated systems. Others can't. The world fractures into zones—automated, abandoned, alternative." He looked at the faces on screen. "Your network? You're building the alternative zones. Places that can function when the optimal systems don't."

Elena smiled. "We asked you to help us understand the systems. You're helping us survive them."

"I designed them. It's the least I can do."

* * *

The risk came in November.

Wei's supervisor called him in. "Chen, there's a security review of your recent communications. Standard protocol, nothing to worry about. Just keep your work devices clean and avoid sensitive topics in personal channels."

Wei's heart raced, but he kept his expression neutral. "Of course. Is there a specific concern?"

"Foreign contacts. Some of your research has high strategic value. We just want to ensure information security."

After the meeting, Wei carefully reviewed his communications. He'd been cautious—encrypted channels, anonymous routing, no direct connections between his official work and network activities.

But he wasn't safe. Just lucky.

He sent Elena a message: *Security review. Need to be more careful. Will reduce contact frequency.*

*Understood. Be safe. What you've shared has already helped thousands of people prepare.*

Wei felt the weight of it. Thousands of people. Learning to be resilient against systems he'd designed to make them dependent.

It wasn't enough to undo the harm. But it was something.

At dinner that night, Lihua mentioned her school was implementing full AI instruction next semester.

"No more human teachers?" Mei asked.

"Just facilitators. The AI does the teaching." Lihua looked at Wei. "They said it's more efficient. Optimal learning outcomes."

Wei met his daughter's eyes. "Efficient isn't the same as good."

"I know, Bàba. You taught me that."

After Lihua went to bed, Wei wrote in his private journal—something he'd started keeping, encrypted and careful.

*I spent fifteen years asking how to make systems optimal. I should have asked what they were for. What purpose they served beyond efficiency.*

*The network understands this. Their systems aren't optimal. But they're purposeful. People using them know why they matter. Know what they're building toward.*

*My systems are efficient. But empty. And I think empty systems eventually fail, no matter how optimal. Because people need meaning more than they need efficiency.*

*Lihua will inherit the world I helped build. A world of perfect systems that don't need humans.*

*I can't undo that. But maybe I can help build spaces where she, and millions like her, still matter. Still have purpose. Still have agency.*

*That's not optimal.*

*But it might be good.*

He closed the journal. Looked out at Beijing's gleaming skyline. Automated systems keeping everything running perfectly.

And somewhere in the margins, people building alternatives. Inefficient, human, meaningful.

Small pictures.

Wei was helping build them now.

It wasn't enough. But it was something.

And something was better than the perfectly optimal nothing he'd designed before.


CRAFT NOTES: CHAPTER SEVEN

Wei as Human, Not Monster

Opens with his modern apartment, his family, his genuine brilliance. He's not a villain—he's someone who believed in optimization and never asked what it was for.

Showing his family life (Lihua, Mei) makes his crisis of conscience personal, not abstract.

Daughter as Moral Compass

Lihua's questions pierce Wei's abstractions:
- "What's left for people?"
- "Is it good?" (not "is it effective?")
- Questions about comparative advantage revealing the control mechanism

She's fifteen and sees clearly what adults rationalize away.

Gradual Realization

Wei's journey from certainty to doubt:
- Elena's first call challenges his assumptions
- Lihua's questions haunt him
- Visiting displaced people makes it personal
- The reception where everyone celebrates "optimal" feels wrong
- Decision to help the network

Each step feels earned, not sudden conversion.

Emotional Contrast

- Pride in his work vs. horror at its implications
- Successful career vs. empty purpose
- Efficient systems vs. displaced humans
- His daughter's future in the world he built

Both feelings coexist. He's not rejecting his work entirely—acknowledging it works, but toward the wrong goal.

The Fatal Flaw Articulated

"They optimized away the only thing that matters. Human meaning."

This is the novel's thesis, delivered by Elena but confirmed by Wei's investigation. The systems work perfectly. That's the problem.

Wei's Contribution to Network

He doesn't become an activist. He uses his expertise:
- Shares knowledge of system vulnerabilities
- Explains what skills matter when automation fails
- Thinks through scenarios
- Identifies fragility in "optimal" systems

This feels authentic to his character—he's still a systems thinker, just applying it differently.

Risk and Stakes

The security review reminds us Wei is taking real risks. He can't openly rebel. Has to be careful. This adds tension and makes his choice more meaningful.

Not Redemption, Just Different

Wei doesn't fully atone for creating dependency systems. He can't undo the harm. But he can help people prepare for when those systems fail.

The ending acknowledges this: "It wasn't enough. But it was something."

Tonal Balance

The chapter has:
- Family warmth (dinners with Lihua and Mei)
- Intellectual challenge (Elena's arguments)
- Personal devastation (talking to displaced workers)
- Quiet resistance (helping the network)
- Uncertain hope (building alternatives)

Not one-note. Entertainment through Wei's internal journey and relationships.

Sets Up Part Four

Wei's analysis that systems will fail in 3-5 years sets the timeline for the coming collapse. His help preparing the network makes their survival in Part Four believable.
